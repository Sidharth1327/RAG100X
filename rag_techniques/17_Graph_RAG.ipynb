{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52776455",
   "metadata": {},
   "source": [
    "## ðŸ•¸ï¸ GraphRAG: Graph-Enhanced Retrieval-Augmented Generation | RAG100X\n",
    "\n",
    "This notebook implements **GraphRAG** â€” an advanced retrieval strategy that combines **graph-based knowledge representation** with retrieval-augmented generation.  \n",
    "\n",
    "Instead of treating document chunks as isolated units, GraphRAG builds a **knowledge graph** where chunks are **nodes** and their relationships (shared concepts, semantic similarity) are **edges**. This enables the system to **walk through related ideas**, preserving context and uncovering deeper connections when answering queries.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… What Youâ€™ll Learn\n",
    "\n",
    "- How to build a **knowledge graph** from document chunks  \n",
    "- How to represent **nodes (text)** and **edges (relationships)**  \n",
    "- How queries are processed using a **graph traversal algorithm**  \n",
    "- Why graphs help maintain **long-range context** across documents  \n",
    "- How visualization reveals the **reasoning path** of the system  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Real-world Analogy\n",
    "\n",
    "Imagine studying history:  \n",
    "\n",
    "> ðŸ“– You first read about the **French Revolution**  \n",
    "> ðŸ”— Then you follow connections to the **Coup of 18 Brumaire**  \n",
    "> ðŸ‘‘ Finally, you see how it links to **Napoleon becoming Emperor**\n",
    "\n",
    "âœ… Thatâ€™s GraphRAG â€” it doesnâ€™t just â€œfetch text,â€ it **follows the chain of connected events** to build a complete, coherent answer.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  How GraphRAG Works Under the Hood\n",
    "\n",
    "| Step                     | What Happens                                                                 |\n",
    "|--------------------------|------------------------------------------------------------------------------|\n",
    "| 1. Document Processing   | Split text into chunks, embed them, and store in a vector DB                 |\n",
    "| 2. Graph Construction    | Create nodes (chunks), extract concepts, add edges for semantic/concept links|\n",
    "| 3. Query Retrieval       | Embed query, fetch initial relevant nodes from vector DB                     |\n",
    "| 4. Graph Traversal       | Use a Dijkstra-like algorithm to walk connected nodes and gather context     |\n",
    "| 5. Answer Generation     | LLM composes a final response from the gathered context                      |\n",
    "| 6. Visualization         | Show nodes, edges, and the traversal path for explainability                 |\n",
    "\n",
    "ðŸ’¡ Unlike flat retrieval, GraphRAG â€œconnects the dotsâ€ and **navigates knowledge like a map**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Why GraphRAG Matters\n",
    "\n",
    "- ðŸ§  **Preserves context**: Links distant but related concepts across docs  \n",
    "- ðŸ” **Smarter retrieval**: Goes beyond keyword match to follow relationships  \n",
    "- ðŸ”Ž **Explainable**: Graph visualization shows *why* an answer was chosen  \n",
    "- âš™ï¸ **Flexible**: Easily integrates new documents and connections  \n",
    "- â© **Efficient**: Prioritizes the strongest knowledge pathways  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ—ï¸ Use Cases Where It Shines\n",
    "\n",
    "- Research papers with interlinked concepts  \n",
    "- Historical or scientific content with **causeâ€“effect chains**  \n",
    "- Knowledge bases where entities are **highly connected**  \n",
    "- Multi-document reasoning tasks that need **traceable context**  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”„ Where This Fits in RAG100X\n",
    "\n",
    "In earlier projects, youâ€™ve built:\n",
    "\n",
    "1. Flat retrieval systems with embeddings + vector stores  \n",
    "2. Context enrichment techniques (CCH, CEW, HyDE, Sub-query Decomp)  \n",
    "3. Reranking and evaluation pipelines  \n",
    "\n",
    "Now, you take a **structural leap**:\n",
    "\n",
    "> ðŸ’¡ **Donâ€™t just store knowledge â€” connect it.**  \n",
    "> GraphRAG transforms isolated chunks into an **interconnected web of reasoning**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install faiss-cpu futures langchain langchain-openai matplotlib networkx nltk numpy python-dotenv scikit-learn spacy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b33843",
   "metadata": {},
   "source": [
    "## ðŸ§° Setup & Imports for GraphRAG | What this cell actually does\n",
    "\n",
    "This cell wires up **all the building blocks** your GraphRAG notebook will need:\n",
    "- Graphs (for relationships and traversal),\n",
    "- Vector search (for semantic lookup),\n",
    "- NLP tools (to extract concepts & normalize terms),\n",
    "- LLM glue (prompts, compression, token/cost tracking),\n",
    "- Viz helpers (to show the graph and the traversal path),\n",
    "- Env and resources (API keys, NLP models).\n",
    "\n",
    "Run this once near the top of your notebook. Nothing â€œbigâ€ happens yet (no indexing/retrieval). Youâ€™re just **loading tools** and **configuring the environment** so later cells can create the knowledge graph and answer queries.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”Ž Big Picture (why these pieces?)\n",
    "\n",
    "| Layer | Purpose | What it enables later |\n",
    "|---|---|---|\n",
    "| **Graph** | Build a knowledge graph from chunks (nodes) + relationships (edges) | Dijkstra-like traversal over â€œmeaningful connectionsâ€ |\n",
    "| **Vector Store** | Fast semantic lookup from embeddings | Seed nodes for traversal; fallback answers |\n",
    "| **NLP** | Concept extraction, normalization (lemmatization), tokenization | Better edges (shared concepts), robust matching |\n",
    "| **LLM Utilities** | Prompting + context compression + token usage tracking | Smaller, sharper contexts + cost visibility |\n",
    "| **Viz** | Matplotlib shapes & arrows | Explainable path visualization |\n",
    "| **Infra** | .env keys, parallelism, progress bars | Stable config, faster preprocessing, user feedback |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ What each import is for (and what happens under the hood)\n",
    "\n",
    "#### Graph & Traversal\n",
    "- `networkx as nx`  \n",
    "  Builds and manipulates the **knowledge graph**. Under the hood, it stores nodes/edges in efficient graph structures and provides algorithms (shortest path, centrality). In GraphRAG, youâ€™ll:\n",
    "  - Create **nodes** = text chunks,\n",
    "  - Create **edges** = relationships (shared concepts, similarity),\n",
    "  - Store **weights** = strength of relationships,\n",
    "  - Traverse with a **priority queue** (Dijkstra-like logic).\n",
    "\n",
    "#### Retrieval & LLM (LangChain + OpenAI)\n",
    "- `FAISS` (from `langchain.vectorstores`)  \n",
    "  A high-performance **similarity search** index. Internally, FAISS builds an index over embeddings so nearest neighbors can be retrieved **fast** (approximate/efficient search vs brute force).\n",
    "- `RecursiveCharacterTextSplitter`  \n",
    "  Splits large text into **overlapping chunks** that preserve coherence (tries to split on paragraphs â†’ sentences â†’ chars). Overlaps keep cross-chunk continuity.\n",
    "- `PromptTemplate`  \n",
    "  Parameterized prompts for LLM calls. Keeps prompts consistent and safe.\n",
    "- `ContextualCompressionRetriever`, `LLMChainExtractor`  \n",
    "  A **two-step retriever**: first retrieve, then **shrink** content with an LLM to keep only the **most relevant lines**. Under the hood, LangChain runs an LLM prompt that *extracts salient spans* from retrieved docs.\n",
    "- `get_openai_callback`  \n",
    "  A context manager that **logs tokens & cost** per LLM call. Great for **cost control** and debugging.\n",
    "\n",
    "- `ChatOpenAI` (from `langchain_openai`)  \n",
    "  LangChainâ€™s wrapper around OpenAI chat models. Handles API calls, retries, temperature, etc.\n",
    "\n",
    "#### Similarity & Math\n",
    "- `cosine_similarity` (scikit-learn)  \n",
    "  Measures **angle similarity** between embeddings (vectors). Used to:\n",
    "  - Build edges between chunks (semantic closeness),\n",
    "  - Re-rank neighbors during traversal.\n",
    "- `numpy as np`  \n",
    "  Efficient **numerical arrays** and math ops.\n",
    "\n",
    "#### NLP (Concepts & Normalization)\n",
    "- `nltk` + `word_tokenize`, `WordNetLemmatizer`  \n",
    "  - **Tokenization**: split text into words/tokens.\n",
    "  - **Lemmatization**: reduce words to **base forms** (e.g., â€œconsulatesâ€ â†’ â€œconsulateâ€). This boosts **matching accuracy** when deciding if two chunks share concepts.\n",
    "- `spacy`, `English`, `spacy.cli.download`  \n",
    "  - SpaCy pipeline powers **entity detection** and **noun chunk extraction** (depending on the model you load).\n",
    "  - `English()` gives a light-weight English pipeline; to use trained models (like `en_core_web_sm`), youâ€™ll typically `spacy.cli.download(\"en_core_web_sm\")` and then `spacy.load(\"en_core_web_sm\")`.  \n",
    "  **Why both NLTK + spaCy?** NLTKâ€™s lemmatizer is simple/reliable; SpaCy gives you faster tokenization, POS tags, entities. Together they help **feature extraction for edges**.\n",
    "\n",
    "#### Priority Queue & Parallelism\n",
    "- `heapq`  \n",
    "  Pythonâ€™s **priority queue**. Critical for the **Dijkstra-like traversal**: always expand the most promising node next (highest score = strongest path to answer).\n",
    "- `ThreadPoolExecutor`, `as_completed`  \n",
    "  **Parallelize** expensive steps (embedding chunks, computing pairwise similarities, extracting concepts). This reduces preprocessing time on multi-core CPUs.\n",
    "\n",
    "#### Progress & Visualization\n",
    "- `tqdm`  \n",
    "  Nice progress bars for long loops (chunking, embedding, graph building).\n",
    "- `matplotlib.pyplot as plt`, `matplotlib.patches as patches`  \n",
    "  Drawing the **graph** and the **traversal path**:\n",
    "  - Nodes as dots/boxes,\n",
    "  - Edge **color/width** = weight strength,\n",
    "  - **Curved/dashed arrows** to highlight the path the algorithm actually took.\n",
    "\n",
    "#### OS & Environment\n",
    "- `os`, `sys`, `dotenv.load_dotenv()`  \n",
    "  - Load **environment variables** (e.g., `OPENAI_API_KEY`) from a local `.env`.\n",
    "  - Manage file paths, optional `sys.path` tweaks.\n",
    "- `os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"`  \n",
    "  Fixes a known OpenMP/MKL warning on some platforms (NumPy/PyTorch). Lets the notebook continue if duplicate OMP libs are detected.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Tuple, Dict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import spacy\n",
    "import heapq\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from spacy.cli import download\n",
    "from spacy.lang.en import English\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086e875",
   "metadata": {},
   "source": [
    "### Understanding the `DocumentProcessor` Class\n",
    "\n",
    "The `DocumentProcessor` class is designed as a **utility for preparing documents** so they can be efficiently used in a Retrieval-Augmented Generation (RAG) system. Letâ€™s break down what it does, why it does it, and what happens under the hood at each step.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Initialization (`__init__`)\n",
    "\n",
    "When a `DocumentProcessor` object is created:\n",
    "\n",
    "- **Text Splitter**:  \n",
    "  It sets up a `RecursiveCharacterTextSplitter` that breaks long documents into smaller overlapping chunks.  \n",
    "  - **Why**: Large documents cannot be directly fed into language models due to context length limits. Splitting ensures that information is captured in manageable pieces.  \n",
    "  - **Under the hood**: It recursively looks for natural breakpoints (paragraphs, sentences, punctuation). If it canâ€™t, it falls back to raw character splits. Each chunk is about 1000 characters, with 200 characters overlapping to preserve context between chunks.\n",
    "\n",
    "- **Embeddings Model**:  \n",
    "  It initializes `OpenAIEmbeddings`, which will later be used to convert text into high-dimensional numeric vectors.  \n",
    "  - **Why**: Text alone cannot be searched efficiently. Converting text into embeddings allows semantic similarity search.  \n",
    "  - **Under the hood**: The embedding model takes each chunk of text and maps it into a vector space (e.g., 1536 dimensions). In this space, semantically similar texts are close to each other.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. `process_documents(documents)`\n",
    "\n",
    "This method takes raw documents and makes them â€œsearch-ready.â€\n",
    "\n",
    "- **Splitting Documents**:  \n",
    "  The text splitter breaks each document into chunks (as explained above).  \n",
    "  - Result: A list of smaller, overlapping text segments.\n",
    "\n",
    "- **Creating a Vector Store (FAISS)**:  \n",
    "  Each chunk is embedded using `OpenAIEmbeddings`, and the embeddings are stored in a FAISS index.  \n",
    "  - **Why FAISS**: FAISS is a specialized library for fast similarity search over large embedding collections. Instead of scanning through every vector, FAISS uses clever indexing structures (like clustering or inverted files) to quickly find the nearest vectors.  \n",
    "  - **Under the hood**: Each embedding vector is inserted into FAISSâ€™s internal index. Later, when you query with another embedding, FAISS computes distances and retrieves the closest matches.\n",
    "\n",
    "- **Output**:  \n",
    "  - `splits`: The list of text chunks.  \n",
    "  - `vector_store`: The FAISS index mapping those chunks to their embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. `create_embeddings_batch(texts, batch_size=32)`\n",
    "\n",
    "This method converts a large number of texts into embeddings in smaller groups (batches).\n",
    "\n",
    "- **Batching**:  \n",
    "  Instead of sending all texts at once, it processes them in groups of 32 by default.  \n",
    "  - **Why**: APIs and GPU models often have limits. Batching prevents overload and makes the process more efficient.  \n",
    "  - **Under the hood**: For each batch, `embed_documents` is called, which makes an API call to the embedding model. The responses are combined into one large list.\n",
    "\n",
    "- **Output**:  \n",
    "  A NumPy array containing all embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. `compute_similarity_matrix(embeddings)`\n",
    "\n",
    "This method calculates how similar each embedding is to every other embedding.\n",
    "\n",
    "- **Cosine Similarity**:  \n",
    "  It uses cosine similarity, which measures the angle between two vectors.  \n",
    "  - **Why**: In embedding space, cosine similarity is a common metric because it focuses on direction rather than magnitude (two texts with similar meaning will point in a similar direction).  \n",
    "  - **Under the hood**: For every pair of embeddings, it computes:  \n",
    "\n",
    "    \\[\n",
    "    \\text{similarity}(A,B) = \\frac{A \\cdot B}{||A|| \\times ||B||}\n",
    "    \\]\n",
    "\n",
    "  - The result is a square matrix where each cell `(i, j)` represents how similar text `i` is to text `j`.\n",
    "\n",
    "- **Output**:  \n",
    "  A 2D NumPy array (matrix) of similarity scores between all texts.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“Œ Why This Matters for RAG\n",
    "\n",
    "1. **Chunking** ensures the LLM can handle large documents.  \n",
    "2. **Embeddings + FAISS** make the document collection searchable by meaning, not just keywords.  \n",
    "3. **Batch embedding** speeds up processing and avoids hitting API limits.  \n",
    "4. **Similarity matrix** helps in analyzing document relationships, clustering, or debugging retrieval quality.  \n",
    "\n",
    "Together, these steps prepare raw documents so that an LLM can later **find, retrieve, and use the most relevant context** when answering questions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DocumentProcessor class\n",
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the DocumentProcessor with a text splitter and OpenAI embeddings.\n",
    "        \n",
    "        Attributes:\n",
    "        - text_splitter: An instance of RecursiveCharacterTextSplitter with specified chunk size and overlap.\n",
    "        - embeddings: An instance of OpenAIEmbeddings used for embedding documents.\n",
    "        \"\"\"\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    def process_documents(self, documents):\n",
    "        \"\"\"\n",
    "        Processes a list of documents by splitting them into smaller chunks and creating a vector store.\n",
    "        \n",
    "        Args:\n",
    "        - documents (list of str): A list of documents to be processed.\n",
    "        \n",
    "        Returns:\n",
    "        - tuple: A tuple containing:\n",
    "          - splits (list of str): The list of split document chunks.\n",
    "          - vector_store (FAISS): A FAISS vector store created from the split document chunks and their embeddings.\n",
    "        \"\"\"\n",
    "        splits = self.text_splitter.split_documents(documents)\n",
    "        vector_store = FAISS.from_documents(splits, self.embeddings)\n",
    "        return splits, vector_store\n",
    "\n",
    "    def create_embeddings_batch(self, texts, batch_size=32):\n",
    "        \"\"\"\n",
    "        Creates embeddings for a list of texts in batches.\n",
    "        \n",
    "        Args:\n",
    "        - texts (list of str): A list of texts to be embedded.\n",
    "        - batch_size (int, optional): The number of texts to process in each batch. Default is 32.\n",
    "        \n",
    "        Returns:\n",
    "        - numpy.ndarray: An array of embeddings for the input texts.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            batch_embeddings = self.embeddings.embed_documents(batch)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def compute_similarity_matrix(self, embeddings):\n",
    "        \"\"\"\n",
    "        Computes a cosine similarity matrix for a given set of embeddings.\n",
    "        \n",
    "        Args:\n",
    "        - embeddings (numpy.ndarray): An array of embeddings.\n",
    "        \n",
    "        Returns:\n",
    "        - numpy.ndarray: A cosine similarity matrix for the input embeddings.\n",
    "        \"\"\"\n",
    "        return cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d514e35",
   "metadata": {},
   "source": [
    "### Understanding the `KnowledgeGraph` Class\n",
    "\n",
    "The `KnowledgeGraph` class is responsible for **turning document chunks into a graph of connected ideas**. Each document chunk becomes a **node**, and connections (edges) are formed between nodes if they are semantically similar and share concepts.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Initialization\n",
    "- **Graph**: Uses `networkx.Graph()` to store nodes (document chunks) and edges (relationships).  \n",
    "- **Lemmatizer**: Reduces words to their base form (e.g., \"running\" â†’ \"run\"). Helps normalize concepts.  \n",
    "- **Concept Cache**: Avoids recalculating concepts for the same text.  \n",
    "- **spaCy NLP Model**: Detects named entities (people, places, orgs, etc.).  \n",
    "- **Edge Threshold**: Similarity score (0.8) above which two nodes should be connected.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Building the Graph (`build_graph`)\n",
    "The pipeline for constructing the graph:\n",
    "1. **Add Nodes** â†’ Each text split becomes a graph node with its content.  \n",
    "2. **Create Embeddings** â†’ Each chunk is embedded into a vector.  \n",
    "3. **Extract Concepts** â†’ Named entities (via spaCy) + general concepts (via LLM).  \n",
    "4. **Add Edges** â†’ Connect nodes if their embeddings are similar enough and they share concepts.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Adding Nodes (`_add_nodes`)\n",
    "- Loops through all text splits.  \n",
    "- Each split is added as a **node** with `page_content`.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Creating Embeddings (`_create_embeddings`)\n",
    "- Converts each chunkâ€™s text into embeddings using the embedding model.  \n",
    "- These embeddings will later be compared for similarity.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Computing Similarities (`_compute_similarities`)\n",
    "- Uses **cosine similarity** to measure how close each embedding is to every other embedding.  \n",
    "- Produces a similarity matrix.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Extracting Concepts\n",
    "- **Named Entities** (via spaCy): Detects proper nouns like names, organizations, and places.  \n",
    "- **General Concepts** (via LLM): Extracts abstract ideas from text.  \n",
    "- **Combination**: Both sets are merged into a list of concepts for each node.  \n",
    "- Uses **multi-threading** for efficiency.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 7. Adding Edges (`_add_edges`)\n",
    "- For every pair of nodes:  \n",
    "  - If similarity > threshold (0.8), check for **shared concepts**.  \n",
    "  - Compute an **edge weight** (blend of similarity score and shared concepts).  \n",
    "  - Add an edge with attributes: weight, similarity, and list of shared concepts.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 8. Edge Weight Calculation\n",
    "\\[\n",
    "\\text{weight} = \\alpha \\times \\text{similarity} + \\beta \\times \\text{normalized shared concepts}\n",
    "\\]  \n",
    "- Default: `Î± = 0.7`, `Î² = 0.3`.  \n",
    "- This ensures edges reflect both semantic closeness and conceptual overlap.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 9. Lemmatizing Concepts (`_lemmatize_concept`)\n",
    "- Converts each concept into its base form.  \n",
    "- Example: `\"running shoes\"` â†’ `\"run shoe\"`.  \n",
    "- Ensures different forms of the same concept link together.  \n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“Œ Why This Matters\n",
    "The class turns raw document chunks into a **knowledge graph**, where:\n",
    "- **Nodes** = pieces of text.  \n",
    "- **Edges** = meaningful relationships (semantic similarity + shared ideas).  \n",
    "\n",
    "This allows for more structured retrieval, making RAG systems not just retrieve â€œsimilar textâ€ but also understand **conceptual connections** between documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf07397",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define the knowledge graph class\n",
    "# Define the Concepts class\n",
    "class Concepts(BaseModel):\n",
    "    concepts_list: List[str] = Field(description=\"List of concepts\")\n",
    "\n",
    "# Define the KnowledgeGraph class\n",
    "class KnowledgeGraph:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the KnowledgeGraph with a graph, lemmatizer, and NLP model.\n",
    "        \n",
    "        Attributes:\n",
    "        - graph: An instance of a networkx Graph.\n",
    "        - lemmatizer: An instance of WordNetLemmatizer.\n",
    "        - concept_cache: A dictionary to cache extracted concepts.\n",
    "        - nlp: An instance of a spaCy NLP model.\n",
    "        - edges_threshold: A float value that sets the threshold for adding edges based on similarity.\n",
    "        \"\"\"\n",
    "        self.graph = nx.Graph()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.concept_cache = {}\n",
    "        self.nlp = self._load_spacy_model()\n",
    "        self.edges_threshold = 0.8\n",
    "\n",
    "    def build_graph(self, splits, llm, embedding_model):\n",
    "        \"\"\"\n",
    "        Builds the knowledge graph by adding nodes, creating embeddings, extracting concepts, and adding edges.\n",
    "        \n",
    "        Args:\n",
    "        - splits (list): A list of document splits.\n",
    "        - llm: An instance of a large language model.\n",
    "        - embedding_model: An instance of an embedding model.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self._add_nodes(splits)\n",
    "        embeddings = self._create_embeddings(splits, embedding_model)\n",
    "        self._extract_concepts(splits, llm)\n",
    "        self._add_edges(embeddings)\n",
    "\n",
    "    def _add_nodes(self, splits):\n",
    "        \"\"\"\n",
    "        Adds nodes to the graph from the document splits.\n",
    "        \n",
    "        Args:\n",
    "        - splits (list): A list of document splits.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        for i, split in enumerate(splits):\n",
    "            self.graph.add_node(i, content=split.page_content)\n",
    "\n",
    "    def _create_embeddings(self, splits, embedding_model):\n",
    "        \"\"\"\n",
    "        Creates embeddings for the document splits using the embedding model.\n",
    "        \n",
    "        Args:\n",
    "        - splits (list): A list of document splits.\n",
    "        - embedding_model: An instance of an embedding model.\n",
    "        \n",
    "        Returns:\n",
    "        - numpy.ndarray: An array of embeddings for the document splits.\n",
    "        \"\"\"\n",
    "        texts = [split.page_content for split in splits]\n",
    "        return embedding_model.embed_documents(texts)\n",
    "\n",
    "    def _compute_similarities(self, embeddings):\n",
    "        \"\"\"\n",
    "        Computes the cosine similarity matrix for the embeddings.\n",
    "        \n",
    "        Args:\n",
    "        - embeddings (numpy.ndarray): An array of embeddings.\n",
    "        \n",
    "        Returns:\n",
    "        - numpy.ndarray: A cosine similarity matrix for the embeddings.\n",
    "        \"\"\"\n",
    "        return cosine_similarity(embeddings)\n",
    "\n",
    "    def _load_spacy_model(self):\n",
    "        \"\"\"\n",
    "        Loads the spaCy NLP model, downloading it if necessary.\n",
    "        \n",
    "        Args:\n",
    "        - None\n",
    "        \n",
    "        Returns:\n",
    "        - spacy.Language: An instance of a spaCy NLP model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            print(\"Downloading spaCy model...\")\n",
    "            download(\"en_core_web_sm\")\n",
    "            return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def _extract_concepts_and_entities(self, content, llm):\n",
    "        \"\"\"\n",
    "        Extracts concepts and named entities from the content using spaCy and a large language model.\n",
    "        \n",
    "        Args:\n",
    "        - content (str): The content from which to extract concepts and entities.\n",
    "        - llm: An instance of a large language model.\n",
    "        \n",
    "        Returns:\n",
    "        - list: A list of extracted concepts and entities.\n",
    "        \"\"\"\n",
    "        if content in self.concept_cache:\n",
    "            return self.concept_cache[content]\n",
    "        \n",
    "        # Extract named entities using spaCy\n",
    "        doc = self.nlp(content)\n",
    "        named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "        \n",
    "        # Extract general concepts using LLM\n",
    "        concept_extraction_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "        )\n",
    "        concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "        general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "        \n",
    "        # Combine named entities and general concepts\n",
    "        all_concepts = list(set(named_entities + general_concepts))\n",
    "        \n",
    "        self.concept_cache[content] = all_concepts\n",
    "        return all_concepts\n",
    "\n",
    "    def _extract_concepts(self, splits, llm):\n",
    "        \"\"\"\n",
    "        Extracts concepts for all document splits using multi-threading.\n",
    "        \n",
    "        Args:\n",
    "        - splits (list): A list of document splits.\n",
    "        - llm: An instance of a large language model.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            future_to_node = {executor.submit(self._extract_concepts_and_entities, split.page_content, llm): i \n",
    "                              for i, split in enumerate(splits)}\n",
    "            \n",
    "            for future in tqdm(as_completed(future_to_node), total=len(splits), desc=\"Extracting concepts and entities\"):\n",
    "                node = future_to_node[future]\n",
    "                concepts = future.result()\n",
    "                self.graph.nodes[node]['concepts'] = concepts\n",
    "\n",
    "    def _add_edges(self, embeddings):\n",
    "        \"\"\"\n",
    "        Adds edges to the graph based on the similarity of embeddings and shared concepts.\n",
    "        \n",
    "        Args:\n",
    "        - embeddings (numpy.ndarray): An array of embeddings for the document splits.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        similarity_matrix = self._compute_similarities(embeddings)\n",
    "        num_nodes = len(self.graph.nodes)\n",
    "        \n",
    "        for node1 in tqdm(range(num_nodes), desc=\"Adding edges\"):\n",
    "            for node2 in range(node1 + 1, num_nodes):\n",
    "                similarity_score = similarity_matrix[node1][node2]\n",
    "                if similarity_score > self.edges_threshold:\n",
    "                    shared_concepts = set(self.graph.nodes[node1]['concepts']) & set(self.graph.nodes[node2]['concepts'])\n",
    "                    edge_weight = self._calculate_edge_weight(node1, node2, similarity_score, shared_concepts)\n",
    "                    self.graph.add_edge(node1, node2, weight=edge_weight, \n",
    "                                        similarity=similarity_score,\n",
    "                                        shared_concepts=list(shared_concepts))\n",
    "\n",
    "    def _calculate_edge_weight(self, node1, node2, similarity_score, shared_concepts, alpha=0.7, beta=0.3):\n",
    "        \"\"\"\n",
    "        Calculates the weight of an edge based on similarity score and shared concepts.\n",
    "        \n",
    "        Args:\n",
    "        - node1 (int): The first node.\n",
    "        - node2 (int): The second node.\n",
    "        - similarity_score (float): The similarity score between the nodes.\n",
    "        - shared_concepts (set): The set of shared concepts between the nodes.\n",
    "        - alpha (float, optional): The weight of the similarity score. Default is 0.7.\n",
    "        - beta (float, optional): The weight of the shared concepts. Default is 0.3.\n",
    "        \n",
    "        Returns:\n",
    "        - float: The calculated weight of the edge.\n",
    "        \"\"\"\n",
    "        max_possible_shared = min(len(self.graph.nodes[node1]['concepts']), len(self.graph.nodes[node2]['concepts']))\n",
    "        normalized_shared_concepts = len(shared_concepts) / max_possible_shared if max_possible_shared > 0 else 0\n",
    "        return alpha * similarity_score + beta * normalized_shared_concepts\n",
    "\n",
    "    def _lemmatize_concept(self, concept):\n",
    "        \"\"\"\n",
    "        Lemmatizes a given concept.\n",
    "        \n",
    "        Args:\n",
    "        - concept (str): The concept to be lemmatized.\n",
    "        \n",
    "        Returns:\n",
    "        - str: The lemmatized concept.\n",
    "        \"\"\"\n",
    "        return ' '.join([self.lemmatizer.lemmatize(word) for word in concept.lower().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required data files\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8462c660",
   "metadata": {},
   "source": [
    "### Understanding the `QueryEngine` Class\n",
    "\n",
    "The `QueryEngine` class is responsible for **answering user queries** by combining:\n",
    "- **Vector search** (to fetch relevant docs quickly)  \n",
    "- **Knowledge graph traversal** (to expand context using relationships)  \n",
    "- **LLM reasoning** (to check if an answer is complete, or generate one if missing)  \n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Initialization\n",
    "- **Vector Store** â†’ Stores embeddings of documents for similarity search.  \n",
    "- **Knowledge Graph** â†’ Graph of concepts & relationships between chunks.  \n",
    "- **LLM** â†’ Used for both concept extraction and final answering.  \n",
    "- **Answer Check Chain** â†’ A small LLM prompt that verifies if context provides a complete answer.  \n",
    "- **Max Context Length** â†’ Keeps context within token budget.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Answer Checking (`_check_answer`)\n",
    "- Takes a **query + context**.  \n",
    "- Asks the LLM: *â€œDoes this context fully answer the query?â€*  \n",
    "- Returns:  \n",
    "  - `is_complete` (True/False)  \n",
    "  - `answer` (if complete).  \n",
    "\n",
    "Example:  \n",
    "> Query: \"Who wrote Hamlet?\"  \n",
    "> Context: \"Hamlet is a tragedy written by William Shakespeare in the early 1600s.\"  \n",
    "âœ… Complete â†’ Answer: \"William Shakespeare\".  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Retrieving Relevant Documents (`_retrieve_relevant_documents`)\n",
    "- Uses the vector store to get top-k similar chunks.  \n",
    "- Compresses them with another LLM step (removes fluff).  \n",
    "- Returns a list of relevant docs to start with.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Expanding Context (`_expand_context`)\n",
    "This is the **core traversal logic**, similar to Dijkstraâ€™s algorithm but adapted for knowledge graphs.  \n",
    "\n",
    "#### Steps:\n",
    "1. **Initialize**  \n",
    "   - Start from the most relevant nodes (from vector search).  \n",
    "   - Push them into a priority queue (priority = inverse of similarity/connection strength).  \n",
    "\n",
    "2. **Traversal**  \n",
    "   - Always pick the node with **highest connection strength**.  \n",
    "   - Add its content to `expanded_context`.  \n",
    "   - Check if context now gives a complete answer.  \n",
    "\n",
    "3. **Concept Handling**  \n",
    "   - Track which concepts have been â€œcoveredâ€.  \n",
    "   - Only expand to neighbors that introduce **new concepts**.  \n",
    "\n",
    "4. **Neighbor Expansion**  \n",
    "   - For each neighbor, calculate new priority (`1 / edge_weight`).  \n",
    "   - If this path is stronger than before, update the queue.  \n",
    "\n",
    "5. **Termination**  \n",
    "   - Stop if a **complete answer** is found.  \n",
    "   - If queue is empty but no complete answer â†’ fallback to LLM to generate one.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Query Flow (`query`)\n",
    "Full end-to-end process:\n",
    "1. **Retrieve relevant docs** via vector store.  \n",
    "2. **Expand context** by traversing knowledge graph.  \n",
    "3. **Check completeness**:  \n",
    "   - If complete â†’ return answer.  \n",
    "   - If incomplete â†’ LLM synthesizes final answer from expanded context.  \n",
    "4. Returns:  \n",
    "   - `final_answer`  \n",
    "   - `traversal_path` (nodes visited)  \n",
    "   - `filtered_content` (mapped node IDs â†’ text).  \n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ“Œ Why This Matters\n",
    "Unlike plain vector search, this approach:\n",
    "- **Understands relationships** between chunks (via graph edges).  \n",
    "- **Expands context meaningfully** (instead of just concatenating top-k).  \n",
    "- **Knows when it has enough info** (via answer check).  \n",
    "- Produces **more reliable and interpretable answers** for complex queries.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AnswerCheck class\n",
    "class AnswerCheck(BaseModel):\n",
    "    is_complete: bool = Field(description=\"Whether the current context provides a complete answer to the query\")\n",
    "    answer: str = Field(description=\"The current answer based on the context, if any\")\n",
    "\n",
    "# Define the QueryEngine class\n",
    "class QueryEngine:\n",
    "    def __init__(self, vector_store, knowledge_graph, llm):\n",
    "        self.vector_store = vector_store\n",
    "        self.knowledge_graph = knowledge_graph\n",
    "        self.llm = llm\n",
    "        self.max_context_length = 4000\n",
    "        self.answer_check_chain = self._create_answer_check_chain()\n",
    "\n",
    "    def _create_answer_check_chain(self):\n",
    "        \"\"\"\n",
    "        Creates a chain to check if the context provides a complete answer to the query.\n",
    "        \n",
    "        Args:\n",
    "        - None\n",
    "        \n",
    "        Returns:\n",
    "        - Chain: A chain to check if the context provides a complete answer.\n",
    "        \"\"\"\n",
    "        answer_check_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"context\"],\n",
    "            template=\"Given the query: '{query}'\\n\\nAnd the current context:\\n{context}\\n\\nDoes this context provide a complete answer to the query? If yes, provide the answer. If no, state that the answer is incomplete.\\n\\nIs complete answer (Yes/No):\\nAnswer (if complete):\"\n",
    "        )\n",
    "        return answer_check_prompt | self.llm.with_structured_output(AnswerCheck)\n",
    "\n",
    "    def _check_answer(self, query: str, context: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Checks if the current context provides a complete answer to the query.\n",
    "        \n",
    "        Args:\n",
    "        - query (str): The query to be answered.\n",
    "        - context (str): The current context.\n",
    "        \n",
    "        Returns:\n",
    "        - tuple: A tuple containing:\n",
    "          - is_complete (bool): Whether the context provides a complete answer.\n",
    "          - answer (str): The answer based on the context, if complete.\n",
    "        \"\"\"\n",
    "        response = self.answer_check_chain.invoke({\"query\": query, \"context\": context})\n",
    "        return response.is_complete, response.answer\n",
    "\n",
    "  \n",
    "\n",
    "    def _expand_context(self, query: str, relevant_docs) -> Tuple[str, List[int], Dict[int, str], str]:\n",
    "        \"\"\"\n",
    "        Expands the context by traversing the knowledge graph using a Dijkstra-like approach.\n",
    "        \n",
    "        This method implements a modified version of Dijkstra's algorithm to explore the knowledge graph,\n",
    "        prioritizing the most relevant and strongly connected information. The algorithm works as follows:\n",
    "\n",
    "        1. Initialize:\n",
    "           - Start with nodes corresponding to the most relevant documents.\n",
    "           - Use a priority queue to manage the traversal order, where priority is based on connection strength.\n",
    "           - Maintain a dictionary of best known \"distances\" (inverse of connection strengths) to each node.\n",
    "\n",
    "        2. Traverse:\n",
    "           - Always explore the node with the highest priority (strongest connection) next.\n",
    "           - For each node, check if we've found a complete answer.\n",
    "           - Explore the node's neighbors, updating their priorities if a stronger connection is found.\n",
    "\n",
    "        3. Concept Handling:\n",
    "           - Track visited concepts to guide the exploration towards new, relevant information.\n",
    "           - Expand to neighbors only if they introduce new concepts.\n",
    "\n",
    "        4. Termination:\n",
    "           - Stop if a complete answer is found.\n",
    "           - Continue until the priority queue is empty (all reachable nodes explored).\n",
    "\n",
    "        This approach ensures that:\n",
    "        - We prioritize the most relevant and strongly connected information.\n",
    "        - We explore new concepts systematically.\n",
    "        - We find the most relevant answer by following the strongest connections in the knowledge graph.\n",
    "\n",
    "        Args:\n",
    "        - query (str): The query to be answered.\n",
    "        - relevant_docs (List[Document]): A list of relevant documents to start the traversal.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: A tuple containing:\n",
    "          - expanded_context (str): The accumulated context from traversed nodes.\n",
    "          - traversal_path (List[int]): The sequence of node indices visited.\n",
    "          - filtered_content (Dict[int, str]): A mapping of node indices to their content.\n",
    "          - final_answer (str): The final answer found, if any.\n",
    "        \"\"\"\n",
    "        # Initialize variables\n",
    "        expanded_context = \"\"\n",
    "        traversal_path = []\n",
    "        visited_concepts = set()\n",
    "        filtered_content = {}\n",
    "        final_answer = \"\"\n",
    "        \n",
    "        priority_queue = []\n",
    "        distances = {}  # Stores the best known \"distance\" (inverse of connection strength) to each node\n",
    "        \n",
    "        print(\"\\nTraversing the knowledge graph:\")\n",
    "        \n",
    "        # Initialize priority queue with closest nodes from relevant docs\n",
    "        for doc in relevant_docs:\n",
    "            # Find the most similar node in the knowledge graph for each relevant document\n",
    "            closest_nodes = self.vector_store.similarity_search_with_score(doc.page_content, k=1)\n",
    "            closest_node_content, similarity_score = closest_nodes[0]\n",
    "            \n",
    "            # Get the corresponding node in our knowledge graph\n",
    "            closest_node = next(n for n in self.knowledge_graph.graph.nodes if self.knowledge_graph.graph.nodes[n]['content'] == closest_node_content.page_content)\n",
    "            \n",
    "            # Initialize priority (inverse of similarity score for min-heap behavior)\n",
    "            priority = 1 / similarity_score\n",
    "            heapq.heappush(priority_queue, (priority, closest_node))\n",
    "            distances[closest_node] = priority\n",
    "        \n",
    "        step = 0\n",
    "        while priority_queue:\n",
    "            # Get the node with the highest priority (lowest distance value)\n",
    "            current_priority, current_node = heapq.heappop(priority_queue)\n",
    "            \n",
    "            # Skip if we've already found a better path to this node\n",
    "            if current_priority > distances.get(current_node, float('inf')):\n",
    "                continue\n",
    "            \n",
    "            if current_node not in traversal_path:\n",
    "                step += 1\n",
    "                traversal_path.append(current_node)\n",
    "                node_content = self.knowledge_graph.graph.nodes[current_node]['content']\n",
    "                node_concepts = self.knowledge_graph.graph.nodes[current_node]['concepts']\n",
    "                \n",
    "                # Add node content to our accumulated context\n",
    "                filtered_content[current_node] = node_content\n",
    "                expanded_context += \"\\n\" + node_content if expanded_context else node_content\n",
    "                \n",
    "                # Log the current step for debugging and visualization\n",
    "                print(f\"\\nStep {step} - Node {current_node}:\")\n",
    "                print(f\"Content: {node_content[:100]}...\") \n",
    "                print(f\"Concepts: {', '.join(node_concepts)}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "                # Check if we have a complete answer with the current context\n",
    "                is_complete, answer = self._check_answer(query, expanded_context)\n",
    "                if is_complete:\n",
    "                    final_answer = answer\n",
    "                    break\n",
    "                \n",
    "                # Process the concepts of the current node\n",
    "                node_concepts_set = set(self.knowledge_graph._lemmatize_concept(c) for c in node_concepts)\n",
    "                if not node_concepts_set.issubset(visited_concepts):\n",
    "                    visited_concepts.update(node_concepts_set)\n",
    "                    \n",
    "                    # Explore neighbors\n",
    "                    for neighbor in self.knowledge_graph.graph.neighbors(current_node):\n",
    "                        edge_data = self.knowledge_graph.graph[current_node][neighbor]\n",
    "                        edge_weight = edge_data['weight']\n",
    "                        \n",
    "                        # Calculate new distance (priority) to the neighbor\n",
    "                        # Note: We use 1 / edge_weight because higher weights mean stronger connections\n",
    "                        distance = current_priority + (1 / edge_weight)\n",
    "                        \n",
    "                        # If we've found a stronger connection to the neighbor, update its distance\n",
    "                        if distance < distances.get(neighbor, float('inf')):\n",
    "                            distances[neighbor] = distance\n",
    "                            heapq.heappush(priority_queue, (distance, neighbor))\n",
    "                            \n",
    "                            # Process the neighbor node if it's not already in our traversal path\n",
    "                            if neighbor not in traversal_path:\n",
    "                                step += 1\n",
    "                                traversal_path.append(neighbor)\n",
    "                                neighbor_content = self.knowledge_graph.graph.nodes[neighbor]['content']\n",
    "                                neighbor_concepts = self.knowledge_graph.graph.nodes[neighbor]['concepts']\n",
    "                                \n",
    "                                filtered_content[neighbor] = neighbor_content\n",
    "                                expanded_context += \"\\n\" + neighbor_content if expanded_context else neighbor_content\n",
    "                                \n",
    "                                # Log the neighbor node information\n",
    "                                print(f\"\\nStep {step} - Node {neighbor} (neighbor of {current_node}):\")\n",
    "                                print(f\"Content: {neighbor_content[:100]}...\")\n",
    "                                print(f\"Concepts: {', '.join(neighbor_concepts)}\")\n",
    "                                print(\"-\" * 50)\n",
    "                                \n",
    "                                # Check if we have a complete answer after adding the neighbor's content\n",
    "                                is_complete, answer = self._check_answer(query, expanded_context)\n",
    "                                if is_complete:\n",
    "                                    final_answer = answer\n",
    "                                    break\n",
    "                                \n",
    "                                # Process the neighbor's concepts\n",
    "                                neighbor_concepts_set = set(self.knowledge_graph._lemmatize_concept(c) for c in neighbor_concepts)\n",
    "                                if not neighbor_concepts_set.issubset(visited_concepts):\n",
    "                                    visited_concepts.update(neighbor_concepts_set)\n",
    "                \n",
    "                # If we found a final answer, break out of the main loop\n",
    "                if final_answer:\n",
    "                    break\n",
    "\n",
    "        # If we haven't found a complete answer, generate one using the LLM\n",
    "        if not final_answer:\n",
    "            print(\"\\nGenerating final answer...\")\n",
    "            response_prompt = PromptTemplate(\n",
    "                input_variables=[\"query\", \"context\"],\n",
    "                template=\"Based on the following context, please answer the query.\\n\\nContext: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "            )\n",
    "            response_chain = response_prompt | self.llm\n",
    "            input_data = {\"query\": query, \"context\": expanded_context}\n",
    "            final_answer = response_chain.invoke(input_data)\n",
    "\n",
    "        return expanded_context, traversal_path, filtered_content, final_answer\n",
    "\n",
    "    def query(self, query: str) -> Tuple[str, List[int], Dict[int, str]]:\n",
    "        \"\"\"\n",
    "        Processes a query by retrieving relevant documents, expanding the context, and generating the final answer.\n",
    "        \n",
    "        Args:\n",
    "        - query (str): The query to be answered.\n",
    "        \n",
    "        Returns:\n",
    "        - tuple: A tuple containing:\n",
    "          - final_answer (str): The final answer to the query.\n",
    "          - traversal_path (list): The traversal path of nodes in the knowledge graph.\n",
    "          - filtered_content (dict): The filtered content of nodes.\n",
    "        \"\"\"\n",
    "        with get_openai_callback() as cb:\n",
    "            print(f\"\\nProcessing query: {query}\")\n",
    "            relevant_docs = self._retrieve_relevant_documents(query)\n",
    "            expanded_context, traversal_path, filtered_content, final_answer = self._expand_context(query, relevant_docs)\n",
    "            \n",
    "            if not final_answer:\n",
    "                print(\"\\nGenerating final answer...\")\n",
    "                response_prompt = PromptTemplate(\n",
    "                    input_variables=[\"query\", \"context\"],\n",
    "                    template=\"Based on the following context, please answer the query.\\n\\nContext: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "                )\n",
    "                \n",
    "                response_chain = response_prompt | self.llm\n",
    "                input_data = {\"query\": query, \"context\": expanded_context}\n",
    "                response = response_chain.invoke(input_data)\n",
    "                final_answer = response\n",
    "            else:\n",
    "                print(\"\\nComplete answer found during traversal.\")\n",
    "            \n",
    "            print(f\"\\nFinal Answer: {final_answer}\")\n",
    "            print(f\"\\nTotal Tokens: {cb.total_tokens}\")\n",
    "            print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "            print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "            print(f\"Total Cost (USD): ${cb.total_cost}\")\n",
    "        \n",
    "        return final_answer, traversal_path, filtered_content\n",
    "\n",
    "    def _retrieve_relevant_documents(self, query: str):\n",
    "        \"\"\"\n",
    "        Retrieves relevant documents based on the query using the vector store.\n",
    "        \n",
    "        Args:\n",
    "        - query (str): The query to be answered.\n",
    "        \n",
    "        Returns:\n",
    "        - list: A list of relevant documents.\n",
    "        \"\"\"\n",
    "        print(\"\\nRetrieving relevant documents...\")\n",
    "        retriever = self.vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "        return compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81509d",
   "metadata": {},
   "source": [
    "# Visualizer Class â€“ Deep Explanation\n",
    "\n",
    "The **Visualizer class** provides two main functionalities:\n",
    "1. **`visualize_traversal`** â†’ Creates a graphical visualization of the traversal path on a knowledge graph.  \n",
    "2. **`print_filtered_content`** â†’ Prints the filtered content of the nodes that were visited during traversal, in the exact order they were explored.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. `visualize_traversal(graph, traversal_path)`\n",
    "\n",
    "This method takes:\n",
    "- A **knowledge graph** (built using NetworkX).\n",
    "- A **traversal path** (a list of node IDs in the order they were visited).  \n",
    "\n",
    "It then generates a **visual flow diagram** showing:\n",
    "- Nodes.\n",
    "- Edges (with weights).\n",
    "- The exact traversal path, highlighted using red arrows.\n",
    "- Start node (highlighted in **green**) and end node (highlighted in **red**).\n",
    "- A legend and color bar for better interpretation.\n",
    "\n",
    "### Step-by-step explanation\n",
    "\n",
    "1. **Initialize a directed graph**  \n",
    "   - Create a new directed graph (`nx.DiGraph`) and copy over all nodes + edges from the original graph.  \n",
    "   - This ensures we have a clean graph specifically for visualization.\n",
    "\n",
    "2. **Set up the figure**  \n",
    "   - Use `matplotlib` to create a canvas (`fig, ax = plt.subplots(figsize=(16, 12))`).  \n",
    "   - The size ensures readability of nodes, labels, and paths.\n",
    "\n",
    "3. **Node positioning**  \n",
    "   - Generate node positions using `spring_layout`.  \n",
    "   - This layout spreads nodes out in a visually pleasing way (like magnets repelling each other).\n",
    "\n",
    "4. **Draw regular edges**  \n",
    "   - Edges are drawn in **blue shades**, where the intensity of the color depends on the **edge weight**.  \n",
    "   - A color map (`plt.cm.Blues`) maps weights to colors.  \n",
    "   - This helps us see which edges are \"stronger\" or more important.\n",
    "\n",
    "5. **Draw nodes**  \n",
    "   - All nodes are drawn as **light blue circles**.  \n",
    "   - Size is large (`3000`) so text labels fit well.\n",
    "\n",
    "6. **Highlight traversal path**  \n",
    "   - For each consecutive pair `(start â†’ end)` in the traversal path:  \n",
    "     - Draw a **red dashed curved arrow** (`FancyArrowPatch`).  \n",
    "     - This makes the traversal stand out compared to regular edges.  \n",
    "   - Arrows are curved slightly (`rad=0.3`) so they donâ€™t overlap with regular edges.\n",
    "\n",
    "7. **Prepare node labels**  \n",
    "   - Each visited node is labeled with the step number and its main concept (if available). Example: `1. Physics`.  \n",
    "   - Non-visited nodes just display their concept name (if any).\n",
    "\n",
    "8. **Highlight start and end nodes**  \n",
    "   - Start node = **light green**.  \n",
    "   - End node = **light coral (red-shaded)**.  \n",
    "   - This makes it immediately clear where traversal began and ended.\n",
    "\n",
    "9. **Color bar for edge weights**  \n",
    "   - Adds a vertical color scale on the side to explain what the blue edge intensities mean (low weight â†’ light blue, high weight â†’ dark blue).\n",
    "\n",
    "10. **Legend**  \n",
    "   - Explains:\n",
    "     - Blue line = regular edge.  \n",
    "     - Red dashed line = traversal path.  \n",
    "     - Green node = start node.  \n",
    "     - Red node = end node.  \n",
    "\n",
    "11. **Show the graph**  \n",
    "   - Finally, `plt.show()` renders the graph for visualization.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. `print_filtered_content(traversal_path, filtered_content)`\n",
    "\n",
    "This method prints the **content of nodes** in the order they were visited.\n",
    "\n",
    "### Step-by-step explanation:\n",
    "\n",
    "1. **Iterate through traversal path**  \n",
    "   - For each step in the traversal, fetch the node ID and its content.\n",
    "\n",
    "2. **Print step details**  \n",
    "   - Example format:  \n",
    "     ```\n",
    "     Step 1 - Node 3:\n",
    "     Filtered Content: Einsteinâ€™s Theory of Relativity emphasizes...\n",
    "     --------------------------------------------------\n",
    "     ```\n",
    "   - Only the **first 200 characters** of the content are shown (to keep output concise).\n",
    "\n",
    "3. **Fallback if no content**  \n",
    "   - If the node has no content, prints: `\"No filtered content available\"`.\n",
    "\n",
    "This provides a **textual log** of what knowledge was encountered along the path, complementing the graphical visualization.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Why is this useful?\n",
    "\n",
    "- **For debugging**: You can see if the traversal followed the right sequence.  \n",
    "- **For learning**: Helps trace knowledge flow step by step.  \n",
    "- **For presentations**: The visualization makes it easier for non-technical stakeholders to understand the graph logic.  \n",
    "- **For analysis**: Edge weights and node labels provide context for why a certain path was chosen.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define the Visualizer class\n",
    "class Visualizer:\n",
    "    @staticmethod\n",
    "    def visualize_traversal(graph, traversal_path):\n",
    "        \"\"\"\n",
    "        Visualizes the traversal path on the knowledge graph with nodes, edges, and traversal path highlighted.\n",
    "\n",
    "        Args:\n",
    "        - graph (networkx.Graph): The knowledge graph containing nodes and edges.\n",
    "        - traversal_path (list of int): The list of node indices representing the traversal path.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        traversal_graph = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes and edges from the original graph\n",
    "        for node in graph.nodes():\n",
    "            traversal_graph.add_node(node)\n",
    "        for u, v, data in graph.edges(data=True):\n",
    "            traversal_graph.add_edge(u, v, **data)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        \n",
    "        # Generate positions for all nodes\n",
    "        pos = nx.spring_layout(traversal_graph, k=1, iterations=50)\n",
    "        \n",
    "        # Draw regular edges with color based on weight\n",
    "        edges = traversal_graph.edges()\n",
    "        edge_weights = [traversal_graph[u][v].get('weight', 0.5) for u, v in edges]\n",
    "        nx.draw_networkx_edges(traversal_graph, pos, \n",
    "                               edgelist=edges,\n",
    "                               edge_color=edge_weights,\n",
    "                               edge_cmap=plt.cm.Blues,\n",
    "                               width=2,\n",
    "                               ax=ax)\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(traversal_graph, pos, \n",
    "                               node_color='lightblue',\n",
    "                               node_size=3000,\n",
    "                               ax=ax)\n",
    "        \n",
    "        # Draw traversal path with curved arrows\n",
    "        edge_offset = 0.1\n",
    "        for i in range(len(traversal_path) - 1):\n",
    "            start = traversal_path[i]\n",
    "            end = traversal_path[i + 1]\n",
    "            start_pos = pos[start]\n",
    "            end_pos = pos[end]\n",
    "            \n",
    "            # Calculate control point for curve\n",
    "            mid_point = ((start_pos[0] + end_pos[0]) / 2, (start_pos[1] + end_pos[1]) / 2)\n",
    "            control_point = (mid_point[0] + edge_offset, mid_point[1] + edge_offset)\n",
    "            \n",
    "            # Draw curved arrow\n",
    "            arrow = patches.FancyArrowPatch(start_pos, end_pos,\n",
    "                                            connectionstyle=f\"arc3,rad={0.3}\",\n",
    "                                            color='red',\n",
    "                                            arrowstyle=\"->\",\n",
    "                                            mutation_scale=20,\n",
    "                                            linestyle='--',\n",
    "                                            linewidth=2,\n",
    "                                            zorder=4)\n",
    "            ax.add_patch(arrow)\n",
    "        \n",
    "        # Prepare labels for the nodes\n",
    "        labels = {}\n",
    "        for i, node in enumerate(traversal_path):\n",
    "            concepts = graph.nodes[node].get('concepts', [])\n",
    "            label = f\"{i + 1}. {concepts[0] if concepts else ''}\"\n",
    "            labels[node] = label\n",
    "        \n",
    "        for node in traversal_graph.nodes():\n",
    "            if node not in labels:\n",
    "                concepts = graph.nodes[node].get('concepts', [])\n",
    "                labels[node] = concepts[0] if concepts else ''\n",
    "        \n",
    "        # Draw labels\n",
    "        nx.draw_networkx_labels(traversal_graph, pos, labels, font_size=8, font_weight=\"bold\", ax=ax)\n",
    "        \n",
    "        # Highlight start and end nodes\n",
    "        start_node = traversal_path[0]\n",
    "        end_node = traversal_path[-1]\n",
    "        \n",
    "        nx.draw_networkx_nodes(traversal_graph, pos, \n",
    "                               nodelist=[start_node], \n",
    "                               node_color='lightgreen', \n",
    "                               node_size=3000,\n",
    "                               ax=ax)\n",
    "        \n",
    "        nx.draw_networkx_nodes(traversal_graph, pos, \n",
    "                               nodelist=[end_node], \n",
    "                               node_color='lightcoral', \n",
    "                               node_size=3000,\n",
    "                               ax=ax)\n",
    "        \n",
    "        ax.set_title(\"Graph Traversal Flow\")\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add colorbar for edge weights\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, norm=plt.Normalize(vmin=min(edge_weights), vmax=max(edge_weights)))\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Edge Weight', rotation=270, labelpad=15)\n",
    "        \n",
    "        # Add legend\n",
    "        regular_line = plt.Line2D([0], [0], color='blue', linewidth=2, label='Regular Edge')\n",
    "        traversal_line = plt.Line2D([0], [0], color='red', linewidth=2, linestyle='--', label='Traversal Path')\n",
    "        start_point = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', markersize=15, label='Start Node')\n",
    "        end_point = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', markersize=15, label='End Node')\n",
    "        legend = plt.legend(handles=[regular_line, traversal_line, start_point, end_point], loc='upper left', bbox_to_anchor=(0, 1), ncol=2)\n",
    "        legend.get_frame().set_alpha(0.8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def print_filtered_content(traversal_path, filtered_content):\n",
    "        \"\"\"\n",
    "        Prints the filtered content of visited nodes in the order of traversal.\n",
    "\n",
    "        Args:\n",
    "        - traversal_path (list of int): The list of node indices representing the traversal path.\n",
    "        - filtered_content (dict of int: str): A dictionary mapping node indices to their filtered content.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        print(\"\\nFiltered content of visited nodes in order of traversal:\")\n",
    "        for i, node in enumerate(traversal_path):\n",
    "            print(f\"\\nStep {i + 1} - Node {node}:\")\n",
    "            print(f\"Filtered Content: {filtered_content.get(node, 'No filtered content available')[:200]}...\")  # Print first 200 characters\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3cc36d",
   "metadata": {},
   "source": [
    "### Explanation of the `GraphRAG` Class\n",
    "\n",
    "The `GraphRAG` class is a high-level orchestrator that ties together all the components needed to build a **graph-based Retrieval-Augmented Generation (RAG) system**. Instead of only relying on vector similarity search (like vanilla RAG), it also builds a **knowledge graph** from documents, enabling more structured reasoning, path traversal, and visualization of how the system derives answers.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”‘ Key Responsibilities of `GraphRAG`\n",
    "\n",
    "1. **Initialization (`__init__`)**  \n",
    "   - **LLM (`ChatOpenAI`)**: The large language model used for generating responses, extracting relationships, and reasoning over graph nodes.  \n",
    "   - **Embedding model (`OpenAIEmbeddings`)**: Transforms document chunks into dense vectors for similarity search.  \n",
    "   - **Document Processor (`DocumentProcessor`)**: Handles chunking of documents and creation of embeddings/vector store.  \n",
    "   - **Knowledge Graph (`KnowledgeGraph`)**: Builds a structured graph of entities and relationships extracted from the documents.  \n",
    "   - **Query Engine (`QueryEngine`)**: Handles the process of interpreting queries, retrieving information from both the vector store and the knowledge graph, and producing a final answer. Initially set to `None` until documents are processed.  \n",
    "   - **Visualizer (`Visualizer`)**: Generates visual representations of how the query traversed the graph, showing the reasoning path.\n",
    "\n",
    "   ðŸ‘‰ Under the hood: At this stage, the system is just setting up its \"tools\" but hasnâ€™t yet ingested any documents.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Processing Documents (`process_documents`)**  \n",
    "   - Splits the raw documents into manageable chunks using the `DocumentProcessor`.  \n",
    "   - Creates embeddings and stores them in a **FAISS vector store** for fast similarity search.  \n",
    "   - Builds a **knowledge graph** where nodes represent entities/concepts and edges represent relationships between them (extracted using the LLM).  \n",
    "   - Instantiates the `QueryEngine`, which knows how to combine vector retrieval + graph traversal for answering queries.\n",
    "\n",
    "   ðŸ‘‰ Under the hood: This step converts **unstructured text** into two structured representations:  \n",
    "   - **Vector space** (good for fuzzy semantic similarity).  \n",
    "   - **Graph structure** (good for explicit reasoning and connections).  \n",
    "\n",
    "   By maintaining both, the system gains **breadth (semantic coverage)** and **depth (logical reasoning through graph paths)**.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Query Handling (`query`)**  \n",
    "   - Accepts a user query as input.  \n",
    "   - Passes it to the `QueryEngine`, which:  \n",
    "     - Retrieves semantically similar chunks from the vector store.  \n",
    "     - Explores the knowledge graph to find connected entities/paths that might be relevant.  \n",
    "     - Combines this evidence to generate a final response with the LLM.  \n",
    "   - Collects additional outputs:  \n",
    "     - **Traversal Path**: The sequence of nodes/edges the system followed in the graph.  \n",
    "     - **Filtered Content**: Subset of document chunks most relevant to the query.  \n",
    "   - If a traversal path exists, calls the `Visualizer` to plot the graph traversal, making the reasoning explainable.  \n",
    "\n",
    "   ðŸ‘‰ Under the hood: This is where the **RAG pipeline activates** â€” the system fuses vector-based recall with graph-based reasoning. Instead of being a black-box LLM response, you can **see the path** of how the system reasoned.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Why This Design?\n",
    "\n",
    "- **Vector Store Only (Vanilla RAG)**: Great for retrieving relevant chunks but limited in reasoning over structured relationships.  \n",
    "- **Graph Only**: Great for explicit knowledge reasoning but brittle if the graph misses relevant details.  \n",
    "- **Graph + Vector Hybrid (GraphRAG)**: Combines the **flexibility of embeddings** with the **structure of graphs**, allowing:  \n",
    "  - Better retrieval quality.  \n",
    "  - Explainability (graph traversal path).  \n",
    "  - Structured knowledge grounding.  \n",
    "\n",
    "In short: **`GraphRAG` enables a more powerful, transparent, and structured RAG system.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphRAG:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the GraphRAG system with components for document processing, knowledge graph construction,\n",
    "        querying, and visualization.\n",
    "        \n",
    "        Attributes:\n",
    "        - llm: An instance of a large language model (LLM) for generating responses.\n",
    "        - embedding_model: An instance of an embedding model for document embeddings.\n",
    "        - document_processor: An instance of the DocumentProcessor class for processing documents.\n",
    "        - knowledge_graph: An instance of the KnowledgeGraph class for building and managing the knowledge graph.\n",
    "        - query_engine: An instance of the QueryEngine class for handling queries (initialized as None).\n",
    "        - visualizer: An instance of the Visualizer class for visualizing the knowledge graph traversal.\n",
    "        \"\"\"\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "        self.embedding_model = OpenAIEmbeddings()\n",
    "        self.document_processor = DocumentProcessor()\n",
    "        self.knowledge_graph = KnowledgeGraph()\n",
    "        self.query_engine = None\n",
    "        self.visualizer = Visualizer()\n",
    "\n",
    "    def process_documents(self, documents):\n",
    "        \"\"\"\n",
    "        Processes a list of documents by splitting them into chunks, embedding them, and building a knowledge graph.\n",
    "        \n",
    "        Args:\n",
    "        - documents (list of str): A list of documents to be processed.\n",
    "        \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        splits, vector_store = self.document_processor.process_documents(documents)\n",
    "        self.knowledge_graph.build_graph(splits, self.llm, self.embedding_model)\n",
    "        self.query_engine = QueryEngine(vector_store, self.knowledge_graph, self.llm)\n",
    "\n",
    "    def query(self, query: str):\n",
    "        \"\"\"\n",
    "        Handles a query by retrieving relevant information from the knowledge graph and visualizing the traversal path.\n",
    "        \n",
    "        Args:\n",
    "        - query (str): The query to be answered.\n",
    "        \n",
    "        Returns:\n",
    "        - str: The response to the query.\n",
    "        \"\"\"\n",
    "        response, traversal_path, filtered_content = self.query_engine.query(query)\n",
    "        \n",
    "        if traversal_path:\n",
    "            self.visualizer.visualize_traversal(self.knowledge_graph.graph, traversal_path)\n",
    "        else:\n",
    "            print(\"No traversal path to visualize.\")\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc12522",
   "metadata": {},
   "source": [
    "### Define documents path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e9e5d",
   "metadata": {},
   "source": [
    "### Create a graph RAG instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b20ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_rag = GraphRAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e20705",
   "metadata": {},
   "source": [
    "### Process the documents and create the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_rag.process_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3786880",
   "metadata": {},
   "source": [
    "### Input a query and get the retrieved information from the graph RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0963cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"what is the main cause of climate change?\"\n",
    "response = graph_rag.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbdd12e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“˜ Summary & Credits\n",
    "\n",
    "This notebook is based on the excellent open-source repository [RAG_Techniques by NirDiamant](https://github.com/NirDiamant/RAG_Techniques).  \n",
    "I referred to that work to understand how the pipeline is structured and then reimplemented the same concept in a **fully self-contained** way, but using recent models â€” as part of my personal learning journey.\n",
    "\n",
    "The purpose of this notebook is purely **educational**:  \n",
    "- To deepen my understanding of Retrieval-Augmented Generation systems  \n",
    "- To keep a clean, trackable log of what Iâ€™ve built and learned  \n",
    "- And to serve as a future reference for myself or others starting from scratch\n",
    "\n",
    "To support that, Iâ€™ve added clear, concise markdowns throughout the notebook â€” explaining *why* each package was installed, *why* each line of code exists, and *how* each component fits into the overall RAG pipeline. Itâ€™s designed to help anyone (including my future self) grasp the **how** and the **why**, not just the **what**.\n",
    "\n",
    "## ðŸ” Why Use Graph-Based Retrieval in RAG?\n",
    "\n",
    "Traditional vector retrieval focuses only on semantic similarity between chunks.  \n",
    "While effective, it often misses **relationships between concepts** that span multiple chunks or documents.  \n",
    "\n",
    "**Graph-Based Retrieval** addresses this by:  \n",
    "- ðŸ§© Capturing **entities and relationships** (knowledge graph) from documents  \n",
    "- ðŸ”— Allowing **multi-hop reasoning** across connected concepts  \n",
    "- ðŸŽ¯ Providing more **contextually coherent answers** by traversing related nodes  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Whatâ€™s New in This Version?\n",
    "\n",
    "This implementation includes:  \n",
    "\n",
    "- ðŸ§± A **GraphRAG class** that integrates LLM, embeddings, document processing, graph building, querying, and visualization  \n",
    "- ðŸ“š **KnowledgeGraph** to represent documents as nodes & edges (entities + relationships)  \n",
    "- ðŸ” **QueryEngine** that combines vector search with graph traversal for enriched retrieval  \n",
    "- ðŸŽ¨ **Visualizer** to display traversal paths, making reasoning transparent  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ˆ Inferences & Key Takeaways\n",
    "\n",
    "- âœ… Ideal for domains with **interconnected facts** (research papers, legal docs, technical manuals)  \n",
    "- ðŸ§  Goes beyond *chunk-level similarity* by **reasoning over structured relationships**  \n",
    "- âš¡ Adds interpretability with traversal visualization (you can see â€œhowâ€ the model answered)  \n",
    "- ðŸ” Bridges the gap between **unstructured text** and **structured reasoning**  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ What Could Be Added Next?\n",
    "\n",
    "- ðŸ“Š Evaluate GraphRAG vs. pure vector retrieval on **accuracy and hallucination reduction**  \n",
    "- ðŸ§ª Extend to **hybrid retrieval** (graph + BM25 + embeddings) for robustness  \n",
    "- ðŸ”— Support **temporal or causal edges** (not just entity links)  \n",
    "- ðŸ§  Add **fallback to global retrieval** if graph traversal fails to find an answer  \n",
    "- âš™ï¸ Explore **graph algorithms** (PageRank, centrality) to prioritize influential nodes  \n",
    "\n",
    "\n",
    "\n",
    "## ðŸ’¡ Final Word\n",
    "\n",
    "This notebook is part of my larger personal project: **RAG100x** â€” a challenge to build and log my journney in RAG from 0 100 in the coming months.\n",
    "\n",
    "Itâ€™s not built to impress â€” itâ€™s built to **progress**.  \n",
    "Everything here is structured to enable **daily iteration**, focused experimentation, and clean documentation.\n",
    "\n",
    "If you're exploring RAG from first principles, feel free to use this as a scaffold for your own builds. And of course â€” check out the original repository for broader implementations and ideas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
